"""
Trace subprocess tree and import into a distributed tracing system

1. Process tree
2. Execution time histogram
3. Import into Jaeger (https://www.jaegertracing.io/)

Based on template generated by perf script -g python
Licensed under the terms of the GNU GPL License version 2


Dependencies
------------

* perf (to execute this script)
* jaeger-client python package (optional)
* a jaeger setup (optional)


Usage
-----

# Start Jaeger (optional, see website for full example)
docker run -d --name jaeger ...

# Record a workload
perf record -g -T -k monotonic \
  -o exectrace.perf.data $workload \
  -e sched:sched_process_exit \
  -e sched:sched_process_fork \
  -e sched:sched_process_exec \
  -e "syscalls:sys_exit_exec*" \
  -e "syscalls:sys_enter_exec*"

# Analyze workload
perf script -i exectrace.perf.data -s execspan.py \
  -- --enable-tree --enable-histogram --enable-jaeger
"""

import argparse
import bisect
import cStringIO
import collections
import datetime
import itertools
import logging
import math
import math
import os
import sys

sys.path.append(os.environ['PERF_EXEC_PATH'] + \
	'/scripts/python/Perf-Trace-Util/lib/Perf/Trace')

from perf_trace_context import *
from Core import *


logging.getLogger('').handlers = []
logging.basicConfig(format='%(message)s', level=logging.INFO)

parser = argparse.ArgumentParser()
parser.add_argument('--enable-tree', dest='enable_tree', action='store_true')
parser.add_argument('--enable-histogram', dest='enable_histogram', action='store_true')
parser.add_argument('--enable-jaeger', dest='enable_jaeger', action='store_true')
parser.add_argument('--time-offset-file', dest='time_offset_file', action='store')
args = parser.parse_args()


class Process(object):

	def __init__(self, time, pid, parent=None, inferred=False):
		self.pid = pid
		self.start_time = time
		self.finish_time = time
		self.inferred = inferred
		self.filename = None
		self.children = []
		self.parent = parent

	def handle_fork(self, time, child_pid):
		child_proc = Process(time, child_pid, parent=self)

		self.children.append(child_proc)
		return child_proc

	def handle_exec(self, time, filename):
		self.filename = filename

	def handle_exec_exit(self, time):
		pass

	def handle_exit(self, time):
		self.finish_time = time

	def __iter__(self):
		return iter(self.children)

	def __str__(self):
		return "%s%%%s" % (self.get_filename(), self.pid)

	def get_filename(self, _parent=False):
		if self.filename:
			return self.filename
		elif self.parent and _parent:
			return self.parent.get_filename(True)
		elif self.parent and not _parent:
			return "(%s)" % self.parent.get_filename(True)
		else:
			return "[unknown]"
	
	def get_pid(self):
		return "%%%s" % self.pid

	@property
	def duration(self):
		if self.start_time and self.finish_time:
			return self.finish_time - self.start_time

	@property
	def duration_str(self):
		duration = self.duration
		if duration:
			return format_time(duration)
		else:
			return "?"
	
	@classmethod
	def get_display_header(cls):
		return "Filename", "PID", "Time"

	def get_display_values(self):
		return self.get_filename(), self.pid, self.duration_str


class ProcessTracker(object):

	# All processes ever seen, in order
	_proc_list = []

	# All currently active processes (pids are not unique over time)
	_pid_to_proc = {}

	def get_by_pid(self, pid):
		return self._pid_to_proc[pid] # may raise KeyError

	def handle_start(self, proc):
		assert proc.pid not in self._pid_to_proc
		self._pid_to_proc[proc.pid] = proc
		self._proc_list.append(proc)
	
	def handle_stop(self, proc):
		assert proc.pid in self._pid_to_proc
		del self._pid_to_proc[proc.pid]

	def __iter__(self):
		return iter(self._proc_list)


def trace_begin():
	global proc_tracker

	proc_tracker = ProcessTracker()

def trace_end():
	global proc_tracker

	if args.enable_tree:\
		trace_end_tree()
	if args.enable_histogram or 1:
		trace_end_histogram()
	if args.enable_jaeger:
		trace_end_jaeger()

def trace_end_tree():
	global proc_tracker

	print_tree_table(
		[proc for proc in proc_tracker if not proc.parent],
		format_func=lambda p: p.get_display_values(),
		header=Process.get_display_header())

def trace_end_histogram():
	global proc_tracker

	print_histogram([p.duration for p in proc_tracker], factor=1e3)

def trace_end_jaeger():
	global proc_tracker

	time_offset = 0.0
	if args.time_offset_file:
		time_offset += os.stat(args.time_offset_file).st_mtime
		time_offset -= max([0.0] + [proc.finish_time or proc.start_time or 0.0 for proc in proc_tracker])

	from jaeger_client import Config

	config = Config(
		config={
			'sampler': {
				'type': 'const',
				'param': 1,
			},
			'logging': False,
		},
		service_name='process',
		validate=True,
	)
	tracer = config.initialize_tracer()

	def walk(proc):
		parent_span = None
		if proc.parent:
			parent_span = proc.parent.span

		start_time = (proc.start_time or 0) + time_offset
		finish_time = (proc.finish_time or 0) + time_offset

		proc.span = tracer.start_span(proc.filename, start_time=start_time, child_of=parent_span)
		proc.span.set_tag("pid", proc.pid)
		proc.span.finish(finish_time=finish_time)

		for sub_proc in proc:
			walk(sub_proc)

	for proc in proc_tracker:
		if proc.parent:
			continue
		walk(proc)

	tracer.close()



def sched__sched_process_fork(event_name, context, common_cpu,
	common_secs, common_nsecs, common_pid, common_comm,
	common_callchain, parent_comm, parent_pid, child_comm, child_pid,
		perf_sample_dict):

	global proc_tracker

	time = common_secs + common_nsecs / 1.0e9

	try:
		parent_proc = proc_tracker.get_by_pid(parent_pid)
	except KeyError:
		parent_proc = Process(time, parent_pid, inferred=True)
		proc_tracker.handle_start(parent_proc)

	child_proc = parent_proc.handle_fork(time, child_pid)
	proc_tracker.handle_start(child_proc)

def syscalls__sys_exit_execve(event_name, context, common_cpu,
	common_secs, common_nsecs, common_pid, common_comm,
	common_callchain, __syscall_nr, ret, perf_sample_dict):

	global proc_tracker

	time = common_secs + common_nsecs / 1.0e9

	try:
		proc = proc_tracker.get_by_pid(common_pid)
	except KeyError:
		proc = Process(time, common_pid, inferred=True)
		proc_tracker.handle_start(proc)

	proc.handle_exec_exit(time)

def sched__sched_process_exec(event_name, context, common_cpu,
	common_secs, common_nsecs, common_pid, common_comm,
	common_callchain, filename, pid, old_pid, perf_sample_dict):

	global proc_tracker

	time = common_secs + common_nsecs / 1.0e9

	try:
		proc = proc_tracker.get_by_pid(common_pid)
	except KeyError:
		proc = Process(time, common_pid, inferred=True)
		proc_tracker.handle_start(proc)

	proc.handle_exec(time, filename)

def syscalls__sys_exit_execveat(event_name, context, common_cpu,
	common_secs, common_nsecs, common_pid, common_comm,
	common_callchain, __syscall_nr, ret, perf_sample_dict):

	return syscalls__sys_exit_execve(event_name, context, common_cpu,
		common_secs, common_nsecs, common_pid, common_comm,
		common_callchain, __syscall_nr, ret, perf_sample_dict)

def syscalls__sys_enter_execve(event_name, context, common_cpu,
	common_secs, common_nsecs, common_pid, common_comm,
	common_callchain, __syscall_nr, filename, argv, envp,
	perf_sample_dict):
	pass

def syscalls__sys_enter_execveat(event_name, context, common_cpu,
	common_secs, common_nsecs, common_pid, common_comm,
	common_callchain, __syscall_nr, fd, filename, argv,
	envp, flags, perf_sample_dict):
	pass

def sched__sched_process_exit(event_name, context, common_cpu,
	common_secs, common_nsecs, common_pid, common_comm,
	common_callchain, comm, pid, prio, perf_sample_dict):

	global proc_tracker

	time = common_secs + common_nsecs / 1.0e9

	try:
		proc = proc_tracker.get_by_pid(common_pid)
	except KeyError:
		proc = Process(time, common_pid, inferred=True)
		proc_tracker.handle_start(proc)

	proc.handle_exit(time)
	proc_tracker.handle_stop(proc)


def print_histogram(vals, factor=1.0):
	num_zeroes = sum(1 for val in vals if val <= 0.0)
	vals = [val * factor for val in vals if not val <= 0.0]

	bin_mins = []
	bin_maxs = []
	bin_counts = []

	# Handle positive values
	if vals:
		max_val = max(vals)
		min_val = min(vals)

		min_bin_exp = int(math.floor(math.log(min_val, 2)))
		max_bin_exp = int(math.floor(math.log(max_val, 2)))

		bin_mins = [2**i for i in xrange(min_bin_exp + 0, max_bin_exp + 1)]
		bin_maxs = bin_mins[1:] + [2**(max_bin_exp+1)]
		bin_counts.extend([0] * len(bin_maxs))

		for val in vals:
			bin_id = bisect.bisect_left(bin_maxs, val)
			bin_counts[bin_id] += 1

	# Handle zero values
	if num_zeroes:
		bin_mins = [0.0] + bin_mins
		bin_maxs = [0.0] + bin_maxs
		bin_counts = [num_zeroes] + bin_counts
	
	# Display
	max_count = max(bin_counts) if bin_counts else 0
	print "%-5s -> %-5s:  %5s  %-40s" % ("Min", "Max", "Count", "Relative frequency")
	for bin_min, bin_max, count in itertools.izip(bin_mins, bin_maxs, bin_counts):
		rel_freq = float(count) / float(len(vals) + num_zeroes)
		rel_freq_str = "%.1f%%" % (100.0 * rel_freq) if count else ""
		print "%-5s -> %-5s:  %5s  |%-40s| %s" % (
			int(bin_min) if bin_min >= 1.0 else round(bin_min, 5),
			int(bin_max) if bin_max >= 1.0 else round(bin_max, 5),
			count if count else "",
			"=" * int(40 * float(count) / float(max_count)),
			rel_freq_str)

def print_tree_table(roots, format_func=lambda x: (x,), child_func=iter, header=None):
	rows = []
	if header:
		rows.append(header)

	# Flatten tree, keeping track of indent level
	def walk_tree(root, indent=0):
		row = map(str, format_func(root))
		row[0] = "    " * indent + row[0]
		rows.append(row)
		for child in child_func(root):
			walk_tree(child, indent+1)
	for root in roots:
		walk_tree(root)

	# Determine column widths
	max_num_cols = max(len(row) for row in rows)
	col_widths = [
		max(len(row[col_idx]) if len(row) > col_idx else 0 for row in rows)
		for col_idx in xrange(max_num_cols)]

	# Print rows
	for row in rows:
		print "  ".join([col.ljust(col_widths[col_idx]) for col_idx, col in enumerate(row)]).rstrip()

def format_stacktrace(common_callchain):
	if not common_callchain:
		return

	stack_buf = cStringIO.StringIO()
	for node in common_callchain:
		if 'sym' in node:
			stack_buf.write("\t[%x] %s\n" % (node['ip'], node['sym']['name']))
		else:
			stack_buf.write("	[%x]\n" % (node['ip']))
	stack_buf.write("\n")

	return stack_buf.getvalue()

def convert_time(num_sec, num_nsec):
	return num_sec + num_nsec * 1.0e9

def format_time(t):
	return "%.2fms" % (t * 1000.0)
